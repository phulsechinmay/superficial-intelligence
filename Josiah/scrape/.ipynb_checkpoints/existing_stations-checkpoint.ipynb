{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "arr = np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {'trip_id': np.str,\n",
    "         'end_station': 'category',\n",
    "         'start_station': 'category',\n",
    "         'trip_route_category': 'category',\n",
    "         'passholder_type': 'category',\n",
    "         'bike_id': np.str,\n",
    "        }\n",
    "rides = pd.read_csv('../data/LABikeData.csv', dtype=dtype, parse_dates=['start_time', 'end_time'], infer_datetime_format=True)\n",
    "names=['station', 'station_name', 'go_live_date', 'region', 'status']\n",
    "dtype=dict(zip(names, ['category', np.str, np.str, np.str, np.str]))\n",
    "stations = pd.read_csv('../data/Station_Table.csv', skiprows=1, names=names, dtype=dtype, parse_dates=['go_live_date'], infer_datetime_format=True)\n",
    "df2.go_live_date = pd.to_datetime(df2.go_live_date)\n",
    "merged = pd.merge(df, df2.add_prefix('start_'), on='start_station', how='left')\n",
    "merged = pd.merge(merged, df2.add_prefix('end_'), on='end_station', how='left')\n",
    "dtla = merged[merged.start_region == 'DTLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides.dataframe() \\\n",
    "    .sort_values(by=\"start_time\",ascending=True) \\\n",
    "    .set_index(\"start_time\")\n",
    "    .last(\"5M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(\"suggested_locations.csv\", dtype={'id': 'category'})\n",
    "comments = pd.read_csv(\"suggested_comments.csv\", dtype={'id': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomments = comments.groupby('id').id.count().rename('ncomments') + 1\n",
    "newdf = stations.join(ncomments, on='id')\n",
    "newdf.ncomments = locations.ncomments.fillna(1)\n",
    "comments_by_station = comments.groupby('id').comment.apply(list).rename('comments')\n",
    "# sns.distplot(ncomments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "locations = newdf.join(comments_by_station, on='id').\\\n",
    "                groupby(['lat', 'lng']).\\\n",
    "                agg({\n",
    "                    'id': 'count',\n",
    "                    'ncomments': 'sum',\n",
    "                    'comment': lambda x: ''.join(x.dropna()),\n",
    "                    'comments': lambda x: list(chain(*x.dropna()))\n",
    "                }).reset_index().rename(columns={'id': 'nstations'})\n",
    "locations.comments = locations.apply(lambda r: r.comments + [r.comment], axis=1)\n",
    "locations = locations.drop('comment', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations[['lat', 'lng' , 'comments', 'ncomments']].\n",
    "    rename(columns={'ncomments':'weight'}).\n",
    "    to_json('latlng.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
